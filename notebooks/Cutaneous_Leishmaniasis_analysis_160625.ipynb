{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258c9857-a40f-448d-9636-dd810fb122d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esm\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "%run \"../scripts/data_processing.py\"\n",
    "%run \"../scripts/node_edge_generation.py\"\n",
    "%run \"../scripts/graph_functions.py\"\n",
    "\n",
    "#Data path\n",
    "datadir = os.path.abspath(\"../../Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0d433-575f-49b1-9867-60d42f5c0fdb",
   "metadata": {},
   "source": [
    "### Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c5a570-cb21-4580-88a3-ba79a0b79ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stopped\n",
      "Database import successful!\n",
      "Graph started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot</th>\n",
       "      <th>Prot_nam</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01611</td>\n",
       "      <td>Immunoglobulin kappa variable 1D-12</td>\n",
       "      <td>0.586821</td>\n",
       "      <td>MDMMVPAQLLGLLLLWFPGSRCDIQMTQSPSSVSASVGDRVTITCR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01709</td>\n",
       "      <td>Immunoglobulin lambda variable 2-8</td>\n",
       "      <td>0.586821</td>\n",
       "      <td>MAWALLLLTLLTQGTGSWAQSALTQPPSASGSPGQSVTISCTGTSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01814</td>\n",
       "      <td>Immunoglobulin heavy variable 2-70</td>\n",
       "      <td>0.586821</td>\n",
       "      <td>MDILCSTLLLLTVPSWVLSQVTLRESGPALVKPTQTLTLTCTFSGF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01768</td>\n",
       "      <td>Immunoglobulin heavy variable 3-30</td>\n",
       "      <td>0.586821</td>\n",
       "      <td>MEFGLSWVFLVALLRGVQCQVQLVESGGGVVQPGRSLRLSCAASGF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2NJV5</td>\n",
       "      <td>Immunoglobulin kappa variable 2-29</td>\n",
       "      <td>0.586821</td>\n",
       "      <td>MRLPAQLLGLLMLWIPGSSADIVMTQTPLSLSVTPGQPASISCKSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>P11912</td>\n",
       "      <td>B-cell antigen receptor complex-associated pro...</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>MPGGPGVLQALPATIFLLFLLSAVYLGPGCQALWMHKVPASLMVSL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>P27361</td>\n",
       "      <td>Mitogen-activated protein kinase 3</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>P29965</td>\n",
       "      <td>CD40 ligand</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>MIETYNQTSPRSAATGLPISMKIFMYLLTVFLITQMIGSALFAVYL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>P35228</td>\n",
       "      <td>Nitric oxide synthase, inducible</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>MACPWKFLFKTKFHQYAMNGEKDINNNVEKAPCATSSPVTQDDLQY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>P35228</td>\n",
       "      <td>Nitric oxide synthase, inducible</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>MACPWKFLFKTKFHQYAMNGEKDINNNVEKAPCATSSPVTQDDLQY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Uniprot                                           Prot_nam     Score  \\\n",
       "0    P01611                Immunoglobulin kappa variable 1D-12  0.586821   \n",
       "1    P01709                 Immunoglobulin lambda variable 2-8  0.586821   \n",
       "2    P01814                 Immunoglobulin heavy variable 2-70  0.586821   \n",
       "3    P01768                 Immunoglobulin heavy variable 3-30  0.586821   \n",
       "4    A2NJV5                 Immunoglobulin kappa variable 2-29  0.586821   \n",
       "..      ...                                                ...       ...   \n",
       "244  P11912  B-cell antigen receptor complex-associated pro...  0.001478   \n",
       "245  P27361                 Mitogen-activated protein kinase 3  0.001478   \n",
       "246  P29965                                        CD40 ligand  0.001478   \n",
       "247  P35228                   Nitric oxide synthase, inducible  0.001478   \n",
       "248  P35228                   Nitric oxide synthase, inducible  0.001478   \n",
       "\n",
       "                                              Sequence  \n",
       "0    MDMMVPAQLLGLLLLWFPGSRCDIQMTQSPSSVSASVGDRVTITCR...  \n",
       "1    MAWALLLLTLLTQGTGSWAQSALTQPPSASGSPGQSVTISCTGTSS...  \n",
       "2    MDILCSTLLLLTVPSWVLSQVTLRESGPALVKPTQTLTLTCTFSGF...  \n",
       "3    MEFGLSWVFLVALLRGVQCQVQLVESGGGVVQPGRSLRLSCAASGF...  \n",
       "4    MRLPAQLLGLLMLWIPGSSADIVMTQTPLSLSVTPGQPASISCKSS...  \n",
       "..                                                 ...  \n",
       "244  MPGGPGVLQALPATIFLLFLLSAVYLGPGCQALWMHKVPASLMVSL...  \n",
       "245  MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQ...  \n",
       "246  MIETYNQTSPRSAATGLPISMKIFMYLLTVFLITQMIGSALFAVYL...  \n",
       "247  MACPWKFLFKTKFHQYAMNGEKDINNNVEKAPCATSSPVTQDDLQY...  \n",
       "248  MACPWKFLFKTKFHQYAMNGEKDINNNVEKAPCATSSPVTQDDLQY...  \n",
       "\n",
       "[249 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start graph\n",
    "startGraph(\"./pass_ent.txt\", \"./Results/\")\n",
    "\n",
    "#Submit query, retrieve sequences with direct cutaneous leishmaniasis associations\n",
    "uri = \"bolt://localhost:7687\" \n",
    "driver = GraphDatabase.driver(uri)\n",
    "\n",
    "query_1 = [f'match (p:Protein)-[di:direct_evidence]-(d:Disease)\\n \\\n",
    "            where  d.name contains \"cutaneous Leishmaniasis\" \\\n",
    "            return p.uniprot as Uniprot, p.name as Prot_nam, toFloat(di.score) as Score, p.seq as Sequence order by Score desc']\n",
    "\n",
    "results_1 = run_query(query_1[0], driver)\n",
    "display(results_1)\n",
    "\n",
    "#Close connection\n",
    "driver.close()\n",
    "\n",
    "#Create subset with smaller sequences\n",
    "smallseqs = results_1.loc[results_1[\"Sequence\"].str.len() <= 1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99f636-b7ee-4217-ba33-6be4b39cc7d6",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1db7cb-3178-4576-b902-682aa7e2ccab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 MB\n",
      "Cached memory: 0.00 MB\n",
      "243 243\n",
      "All matched!\n"
     ]
    }
   ],
   "source": [
    "#Reset gpu resource usage\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "querydf = smallseqs\n",
    "\n",
    "# Load ESM-2 model\n",
    "#https://github.com/facebookresearch/esm#available-models\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "#Split to test + train datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(len(smallseqs[\"Sequence\"].values), len(smallseqs[\"Uniprot\"].values))\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(smallseqs[\"Sequence\"].values, smallseqs[\"Uniprot\"].values, test_size=0.25, shuffle=True)\n",
    "\n",
    "#Prepare sequences for tokenisation\n",
    "trainlist = []\n",
    "for i, j in zip(train_labels, train_sequences):\n",
    "    trainlist.append((i, j))\n",
    "testlist = []\n",
    "for i, j in zip(test_labels, test_sequences):\n",
    "    testlist.append((i, j))\n",
    "\n",
    "#Check test/train list match Uniprot <> seq labels\n",
    "res = []\n",
    "for i in trainlist+testlist:\n",
    "    res.append(smallseqs.loc[smallseqs[\"Uniprot\"] == i[0]][\"Sequence\"].values[0] == i[1])\n",
    "if False in res:\n",
    "    print(\"Mismatch!\")\n",
    "else:\n",
    "    print(\"All matched!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f17d2-3d85-4f15-a0ea-3804395f7375",
   "metadata": {},
   "source": [
    "### Sequence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52984172-b331-49b3-99b3-359d133a0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken (Embedding (batch 0)) = 0.79 seconds \t| Total (0.79)\n",
      "Time taken (Embedding (batch 1)) = 0.77 seconds \t| Total (1.56)\n",
      "Time taken (Embedding (batch 2)) = 0.75 seconds \t| Total (2.31)\n",
      "Time taken (Embedding (batch 3)) = 0.75 seconds \t| Total (3.06)\n",
      "Time taken (Embedding (batch 4)) = 0.75 seconds \t| Total (3.82)\n",
      "Time taken (Embedding (batch 5)) = 0.75 seconds \t| Total (4.57)\n",
      "Time taken (Embedding (batch 6)) = 0.76 seconds \t| Total (5.32)\n",
      "Time taken (Embedding (batch 7)) = 0.79 seconds \t| Total (6.11)\n",
      "Time taken (Embedding (batch 8)) = 0.75 seconds \t| Total (6.86)\n",
      "Time taken (Embedding (batch 9)) = 0.75 seconds \t| Total (7.61)\n",
      "Time taken (Embedding (batch 10)) = 0.78 seconds \t| Total (8.39)\n",
      "Time taken (Embedding (batch 11)) = 0.76 seconds \t| Total (9.14)\n",
      "Time taken (Embedding (batch 12)) = 0.75 seconds \t| Total (9.89)\n",
      "Time taken (Embedding (batch 13)) = 0.75 seconds \t| Total (10.64)\n",
      "Time taken (Embedding (batch 14)) = 0.76 seconds \t| Total (11.4)\n",
      "Time taken (Embedding (batch 15)) = 0.75 seconds \t| Total (12.15)\n",
      "Time taken (Embedding (batch 16)) = 0.74 seconds \t| Total (12.9)\n",
      "Time taken (Embedding (batch 17)) = 0.76 seconds \t| Total (13.66)\n",
      "Time taken (Embedding (batch 18)) = 0.75 seconds \t| Total (14.41)\n",
      "Time taken (Embedding (batch 19)) = 0.76 seconds \t| Total (15.16)\n",
      "Time taken (Embedding (batch 20)) = 0.75 seconds \t| Total (15.91)\n",
      "Time taken (Embedding (batch 21)) = 0.75 seconds \t| Total (16.66)\n",
      "Time taken (Embedding (batch 22)) = 0.76 seconds \t| Total (17.42)\n",
      "Time taken (Embedding (batch 23)) = 0.76 seconds \t| Total (18.17)\n",
      "Time taken (Embedding (batch 24)) = 0.75 seconds \t| Total (18.92)\n",
      "Time taken (Embedding (batch 25)) = 0.75 seconds \t| Total (19.68)\n",
      "Time taken (Embedding (batch 26)) = 0.75 seconds \t| Total (20.43)\n",
      "Time taken (Embedding (batch 27)) = 0.75 seconds \t| Total (21.18)\n",
      "Time taken (Embedding (batch 28)) = 0.75 seconds \t| Total (21.93)\n",
      "Time taken (Embedding (batch 29)) = 0.76 seconds \t| Total (22.69)\n",
      "Time taken (Embedding (batch 30)) = 0.75 seconds \t| Total (23.44)\n",
      "Time taken (Embedding (batch 31)) = 0.76 seconds \t| Total (24.2)\n",
      "Time taken (Embedding (batch 32)) = 0.75 seconds \t| Total (24.94)\n",
      "Time taken (Embedding (batch 33)) = 0.76 seconds \t| Total (25.71)\n",
      "Time taken (Embedding (batch 34)) = 0.75 seconds \t| Total (26.46)\n",
      "Time taken (Embedding (batch 35)) = 0.76 seconds \t| Total (27.22)\n",
      "Time taken (Embedding (batch 36)) = 0.76 seconds \t| Total (27.97)\n",
      "Time taken (Embedding (batch 37)) = 0.75 seconds \t| Total (28.72)\n",
      "Time taken (Embedding (batch 38)) = 0.76 seconds \t| Total (29.48)\n",
      "Time taken (Embedding (batch 39)) = 0.77 seconds \t| Total (30.24)\n",
      "Time taken (Embedding (batch 40)) = 0.75 seconds \t| Total (31.0)\n",
      "Time taken (Embedding (batch 41)) = 0.76 seconds \t| Total (31.75)\n",
      "Time taken (Embedding (batch 42)) = 0.75 seconds \t| Total (32.5)\n",
      "Time taken (Embedding (batch 43)) = 0.75 seconds \t| Total (33.26)\n",
      "Time taken (Embedding (batch 44)) = 0.75 seconds \t| Total (34.01)\n",
      "Time taken (Embedding (batch 45)) = 0.75 seconds \t| Total (34.77)\n",
      "Time taken (Embedding (batch 46)) = 0.68 seconds \t| Total (35.44)\n",
      "Time taken (Embedding (batch 47)) = 0.76 seconds \t| Total (36.2)\n",
      "Time taken (Embedding (batch 48)) = 0.75 seconds \t| Total (36.96)\n",
      "Time taken (Embedding (batch 49)) = 0.76 seconds \t| Total (37.72)\n",
      "Time taken (Embedding (batch 50)) = 0.75 seconds \t| Total (38.47)\n",
      "Time taken (Embedding (batch 51)) = 0.76 seconds \t| Total (39.23)\n",
      "Time taken (Embedding (batch 52)) = 0.76 seconds \t| Total (39.99)\n",
      "Time taken (Embedding (batch 53)) = 0.76 seconds \t| Total (40.75)\n",
      "Time taken (Embedding (batch 54)) = 0.75 seconds \t| Total (41.5)\n",
      "Time taken (Embedding (batch 55)) = 0.76 seconds \t| Total (42.26)\n",
      "Time taken (Embedding (batch 56)) = 0.75 seconds \t| Total (43.01)\n",
      "Time taken (Embedding (batch 57)) = 0.76 seconds \t| Total (43.76)\n",
      "Time taken (Embedding (batch 58)) = 0.75 seconds \t| Total (44.51)\n",
      "Time taken (Embedding (batch 59)) = 0.76 seconds \t| Total (45.28)\n",
      "Time taken (Embedding (batch 60)) = 0.76 seconds \t| Total (46.04)\n",
      "Time taken (Embedding (batch 0)) = 0.78 seconds \t| Total (0.78)\n",
      "Time taken (Embedding (batch 1)) = 0.79 seconds \t| Total (1.58)\n",
      "Time taken (Embedding (batch 2)) = 0.79 seconds \t| Total (2.36)\n",
      "Time taken (Embedding (batch 3)) = 0.79 seconds \t| Total (3.15)\n",
      "Time taken (Embedding (batch 4)) = 0.79 seconds \t| Total (3.94)\n",
      "Time taken (Embedding (batch 5)) = 0.78 seconds \t| Total (4.72)\n",
      "Time taken (Embedding (batch 6)) = 0.79 seconds \t| Total (5.51)\n",
      "Time taken (Embedding (batch 7)) = 0.79 seconds \t| Total (6.3)\n",
      "Time taken (Embedding (batch 8)) = 0.79 seconds \t| Total (7.09)\n",
      "Time taken (Embedding (batch 9)) = 0.79 seconds \t| Total (7.88)\n",
      "Time taken (Embedding (batch 10)) = 0.79 seconds \t| Total (8.67)\n",
      "Time taken (Embedding (batch 11)) = 0.79 seconds \t| Total (9.47)\n",
      "Time taken (Embedding (batch 12)) = 0.79 seconds \t| Total (10.26)\n",
      "Time taken (Embedding (batch 13)) = 0.83 seconds \t| Total (11.09)\n",
      "Time taken (Embedding (batch 14)) = 0.79 seconds \t| Total (11.88)\n",
      "Time taken (Embedding (batch 15)) = 0.8 seconds \t| Total (12.68)\n",
      "Time taken (Embedding (batch 16)) = 0.83 seconds \t| Total (13.5)\n",
      "Time taken (Embedding (batch 17)) = 0.83 seconds \t| Total (14.33)\n",
      "Time taken (Embedding (batch 18)) = 0.82 seconds \t| Total (15.16)\n",
      "Time taken (Embedding (batch 19)) = 0.8 seconds \t| Total (15.95)\n",
      "Time taken (Embedding (batch 20)) = 0.79 seconds \t| Total (16.75)\n",
      "Time taken (Embedding (batch 21)) = 0.84 seconds \t| Total (17.58)\n",
      "Time taken (Embedding (batch 22)) = 0.84 seconds \t| Total (18.42)\n",
      "Time taken (Embedding (batch 23)) = 0.85 seconds \t| Total (19.27)\n",
      "Time taken (Embedding (batch 24)) = 0.8 seconds \t| Total (20.07)\n",
      "Time taken (Embedding (batch 25)) = 0.82 seconds \t| Total (20.9)\n",
      "Time taken (Embedding (batch 26)) = 0.79 seconds \t| Total (21.69)\n",
      "Time taken (Embedding (batch 27)) = 0.84 seconds \t| Total (22.52)\n",
      "Time taken (Embedding (batch 28)) = 0.81 seconds \t| Total (23.34)\n",
      "Time taken (Embedding (batch 29)) = 0.79 seconds \t| Total (24.12)\n",
      "Time taken (Embedding (batch 30)) = 0.8 seconds \t| Total (24.92)\n",
      "Time taken (Embedding (batch 31)) = 0.83 seconds \t| Total (25.75)\n",
      "Time taken (Embedding (batch 32)) = 0.8 seconds \t| Total (26.55)\n",
      "Time taken (Embedding (batch 33)) = 0.83 seconds \t| Total (27.39)\n",
      "Time taken (Embedding (batch 34)) = 0.84 seconds \t| Total (28.23)\n",
      "Time taken (Embedding (batch 35)) = 0.86 seconds \t| Total (29.08)\n",
      "Time taken (Embedding (batch 36)) = 0.85 seconds \t| Total (29.93)\n",
      "Time taken (Embedding (batch 37)) = 0.83 seconds \t| Total (30.76)\n",
      "Time taken (Embedding (batch 38)) = 0.79 seconds \t| Total (31.55)\n",
      "Time taken (Embedding (batch 39)) = 0.79 seconds \t| Total (32.34)\n",
      "Time taken (Embedding (batch 40)) = 0.81 seconds \t| Total (33.15)\n",
      "Time taken (Embedding (batch 41)) = 0.82 seconds \t| Total (33.96)\n",
      "Time taken (Embedding (batch 42)) = 0.79 seconds \t| Total (34.75)\n",
      "Time taken (Embedding (batch 43)) = 0.81 seconds \t| Total (35.56)\n",
      "Time taken (Embedding (batch 44)) = 0.8 seconds \t| Total (36.36)\n",
      "Time taken (Embedding (batch 45)) = 0.81 seconds \t| Total (37.17)\n",
      "Time taken (Embedding (batch 46)) = 0.79 seconds \t| Total (37.95)\n",
      "Time taken (Embedding (batch 47)) = 0.81 seconds \t| Total (38.77)\n",
      "Time taken (Embedding (batch 48)) = 0.82 seconds \t| Total (39.59)\n",
      "Time taken (Embedding (batch 49)) = 0.79 seconds \t| Total (40.38)\n",
      "Time taken (Embedding (batch 50)) = 0.79 seconds \t| Total (41.16)\n",
      "Time taken (Embedding (batch 51)) = 0.82 seconds \t| Total (41.98)\n",
      "Time taken (Embedding (batch 52)) = 0.82 seconds \t| Total (42.79)\n",
      "Time taken (Embedding (batch 53)) = 0.79 seconds \t| Total (43.58)\n",
      "Time taken (Embedding (batch 54)) = 0.78 seconds \t| Total (44.37)\n",
      "Time taken (Embedding (batch 55)) = 0.81 seconds \t| Total (45.18)\n",
      "Time taken (Embedding (batch 56)) = 0.8 seconds \t| Total (45.98)\n",
      "Time taken (Embedding (batch 57)) = 0.81 seconds \t| Total (46.79)\n",
      "Time taken (Embedding (batch 58)) = 0.8 seconds \t| Total (47.58)\n",
      "Time taken (Embedding (batch 59)) = 0.81 seconds \t| Total (48.39)\n",
      "Time taken (Embedding (batch 60)) = 0.79 seconds \t| Total (49.18)\n",
      "Time taken (Embedding (batch 61)) = 0.79 seconds \t| Total (49.97)\n",
      "Time taken (Embedding (batch 62)) = 0.83 seconds \t| Total (50.8)\n",
      "Time taken (Embedding (batch 63)) = 0.81 seconds \t| Total (51.61)\n",
      "Time taken (Embedding (batch 64)) = 0.82 seconds \t| Total (52.43)\n",
      "Time taken (Embedding (batch 65)) = 0.79 seconds \t| Total (53.21)\n",
      "Time taken (Embedding (batch 66)) = 0.79 seconds \t| Total (54.0)\n",
      "Time taken (Embedding (batch 67)) = 0.82 seconds \t| Total (54.82)\n",
      "Time taken (Embedding (batch 68)) = 0.79 seconds \t| Total (55.61)\n",
      "Time taken (Embedding (batch 69)) = 0.81 seconds \t| Total (56.42)\n",
      "Time taken (Embedding (batch 70)) = 0.82 seconds \t| Total (57.24)\n",
      "Time taken (Embedding (batch 71)) = 0.79 seconds \t| Total (58.03)\n",
      "Time taken (Embedding (batch 72)) = 0.81 seconds \t| Total (58.84)\n",
      "Time taken (Embedding (batch 73)) = 0.79 seconds \t| Total (59.63)\n",
      "Time taken (Embedding (batch 74)) = 0.82 seconds \t| Total (60.45)\n",
      "Time taken (Embedding (batch 75)) = 0.8 seconds \t| Total (61.25)\n",
      "Time taken (Embedding (batch 76)) = 0.81 seconds \t| Total (62.06)\n",
      "Time taken (Embedding (batch 77)) = 0.79 seconds \t| Total (62.85)\n",
      "Time taken (Embedding (batch 78)) = 0.79 seconds \t| Total (63.64)\n",
      "Time taken (Embedding (batch 79)) = 0.79 seconds \t| Total (64.43)\n",
      "Time taken (Embedding (batch 80)) = 0.78 seconds \t| Total (65.21)\n",
      "Time taken (Embedding (batch 81)) = 0.83 seconds \t| Total (66.04)\n",
      "Time taken (Embedding (batch 82)) = 0.82 seconds \t| Total (66.85)\n",
      "Time taken (Embedding (batch 83)) = 0.82 seconds \t| Total (67.68)\n",
      "Time taken (Embedding (batch 84)) = 0.8 seconds \t| Total (68.48)\n",
      "Time taken (Embedding (batch 85)) = 0.8 seconds \t| Total (69.28)\n",
      "Time taken (Embedding (batch 86)) = 0.81 seconds \t| Total (70.09)\n",
      "Time taken (Embedding (batch 87)) = 0.79 seconds \t| Total (70.88)\n",
      "Time taken (Embedding (batch 88)) = 0.81 seconds \t| Total (71.7)\n",
      "Time taken (Embedding (batch 89)) = 0.79 seconds \t| Total (72.48)\n",
      "Time taken (Embedding (batch 90)) = 0.78 seconds \t| Total (73.27)\n",
      "Time taken (Embedding (batch 91)) = 0.79 seconds \t| Total (74.05)\n",
      "Time taken (Embedding (batch 92)) = 0.79 seconds \t| Total (74.84)\n",
      "Time taken (Embedding (batch 93)) = 0.79 seconds \t| Total (75.63)\n",
      "Time taken (Embedding (batch 94)) = 0.79 seconds \t| Total (76.41)\n",
      "Time taken (Embedding (batch 95)) = 0.78 seconds \t| Total (77.2)\n",
      "Time taken (Embedding (batch 96)) = 0.78 seconds \t| Total (77.98)\n",
      "Time taken (Embedding (batch 97)) = 0.78 seconds \t| Total (78.77)\n",
      "Time taken (Embedding (batch 98)) = 0.79 seconds \t| Total (79.55)\n",
      "Time taken (Embedding (batch 99)) = 0.78 seconds \t| Total (80.33)\n",
      "Time taken (Embedding (batch 100)) = 0.79 seconds \t| Total (81.12)\n",
      "Time taken (Embedding (batch 101)) = 0.81 seconds \t| Total (81.93)\n",
      "Time taken (Embedding (batch 102)) = 0.8 seconds \t| Total (82.73)\n",
      "Time taken (Embedding (batch 103)) = 0.8 seconds \t| Total (83.53)\n",
      "Time taken (Embedding (batch 104)) = 0.78 seconds \t| Total (84.31)\n",
      "Time taken (Embedding (batch 105)) = 0.78 seconds \t| Total (85.09)\n",
      "Time taken (Embedding (batch 106)) = 0.79 seconds \t| Total (85.88)\n",
      "Time taken (Embedding (batch 107)) = 0.78 seconds \t| Total (86.67)\n",
      "Time taken (Embedding (batch 108)) = 0.79 seconds \t| Total (87.45)\n",
      "Time taken (Embedding (batch 109)) = 0.79 seconds \t| Total (88.25)\n",
      "Time taken (Embedding (batch 110)) = 0.79 seconds \t| Total (89.03)\n",
      "Time taken (Embedding (batch 111)) = 0.79 seconds \t| Total (89.82)\n",
      "Time taken (Embedding (batch 112)) = 0.79 seconds \t| Total (90.61)\n",
      "Time taken (Embedding (batch 113)) = 0.78 seconds \t| Total (91.39)\n",
      "Time taken (Embedding (batch 114)) = 0.79 seconds \t| Total (92.18)\n",
      "Time taken (Embedding (batch 115)) = 0.78 seconds \t| Total (92.97)\n",
      "Time taken (Embedding (batch 116)) = 0.79 seconds \t| Total (93.76)\n",
      "Time taken (Embedding (batch 117)) = 0.79 seconds \t| Total (94.55)\n",
      "Time taken (Embedding (batch 118)) = 0.81 seconds \t| Total (95.36)\n",
      "Time taken (Embedding (batch 119)) = 0.79 seconds \t| Total (96.14)\n",
      "Time taken (Embedding (batch 120)) = 0.79 seconds \t| Total (96.94)\n",
      "Time taken (Embedding (batch 121)) = 0.81 seconds \t| Total (97.74)\n",
      "Time taken (Embedding (batch 122)) = 0.78 seconds \t| Total (98.53)\n",
      "Time taken (Embedding (batch 123)) = 0.79 seconds \t| Total (99.32)\n",
      "Time taken (Embedding (batch 124)) = 0.82 seconds \t| Total (100.13)\n",
      "Time taken (Embedding (batch 125)) = 0.79 seconds \t| Total (100.92)\n",
      "Time taken (Embedding (batch 126)) = 0.79 seconds \t| Total (101.71)\n",
      "Time taken (Embedding (batch 127)) = 0.8 seconds \t| Total (102.51)\n",
      "Time taken (Embedding (batch 128)) = 0.78 seconds \t| Total (103.3)\n",
      "Time taken (Embedding (batch 129)) = 0.8 seconds \t| Total (104.1)\n",
      "Time taken (Embedding (batch 130)) = 0.78 seconds \t| Total (104.88)\n",
      "Time taken (Embedding (batch 131)) = 0.8 seconds \t| Total (105.69)\n",
      "Time taken (Embedding (batch 132)) = 0.8 seconds \t| Total (106.49)\n",
      "Time taken (Embedding (batch 133)) = 0.84 seconds \t| Total (107.32)\n",
      "Time taken (Embedding (batch 134)) = 0.79 seconds \t| Total (108.11)\n",
      "Time taken (Embedding (batch 135)) = 0.78 seconds \t| Total (108.89)\n",
      "Time taken (Embedding (batch 136)) = 0.79 seconds \t| Total (109.68)\n",
      "Time taken (Embedding (batch 137)) = 0.79 seconds \t| Total (110.47)\n",
      "Time taken (Embedding (batch 138)) = 0.79 seconds \t| Total (111.26)\n",
      "Time taken (Embedding (batch 139)) = 0.79 seconds \t| Total (112.04)\n",
      "Time taken (Embedding (batch 140)) = 0.79 seconds \t| Total (112.83)\n",
      "Time taken (Embedding (batch 141)) = 0.79 seconds \t| Total (113.62)\n",
      "Time taken (Embedding (batch 142)) = 0.79 seconds \t| Total (114.41)\n",
      "Time taken (Embedding (batch 143)) = 0.68 seconds \t| Total (115.09)\n",
      "Time taken (Embedding (batch 144)) = 0.79 seconds \t| Total (115.88)\n",
      "Time taken (Embedding (batch 145)) = 0.78 seconds \t| Total (116.67)\n",
      "Time taken (Embedding (batch 146)) = 0.79 seconds \t| Total (117.45)\n",
      "Time taken (Embedding (batch 147)) = 0.79 seconds \t| Total (118.24)\n",
      "Time taken (Embedding (batch 148)) = 0.79 seconds \t| Total (119.03)\n",
      "Time taken (Embedding (batch 149)) = 0.81 seconds \t| Total (119.85)\n",
      "Time taken (Embedding (batch 150)) = 0.81 seconds \t| Total (120.66)\n",
      "Time taken (Embedding (batch 151)) = 0.83 seconds \t| Total (121.48)\n",
      "Time taken (Embedding (batch 152)) = 0.79 seconds \t| Total (122.27)\n",
      "Time taken (Embedding (batch 153)) = 0.79 seconds \t| Total (123.06)\n",
      "Time taken (Embedding (batch 154)) = 0.79 seconds \t| Total (123.85)\n",
      "Time taken (Embedding (batch 155)) = 0.79 seconds \t| Total (124.64)\n",
      "Time taken (Embedding (batch 156)) = 0.82 seconds \t| Total (125.45)\n",
      "Time taken (Embedding (batch 157)) = 0.79 seconds \t| Total (126.24)\n",
      "Time taken (Embedding (batch 158)) = 0.79 seconds \t| Total (127.03)\n",
      "Time taken (Embedding (batch 159)) = 0.81 seconds \t| Total (127.83)\n",
      "Time taken (Embedding (batch 160)) = 0.8 seconds \t| Total (128.64)\n",
      "Time taken (Embedding (batch 161)) = 0.79 seconds \t| Total (129.42)\n",
      "Time taken (Embedding (batch 162)) = 0.79 seconds \t| Total (130.21)\n",
      "Time taken (Embedding (batch 163)) = 0.82 seconds \t| Total (131.03)\n",
      "Time taken (Embedding (batch 164)) = 0.79 seconds \t| Total (131.82)\n",
      "Time taken (Embedding (batch 165)) = 0.83 seconds \t| Total (132.65)\n",
      "Time taken (Embedding (batch 166)) = 0.79 seconds \t| Total (133.44)\n",
      "Time taken (Embedding (batch 167)) = 0.79 seconds \t| Total (134.23)\n",
      "Time taken (Embedding (batch 168)) = 0.79 seconds \t| Total (135.02)\n",
      "Time taken (Embedding (batch 169)) = 0.79 seconds \t| Total (135.8)\n",
      "Time taken (Embedding (batch 170)) = 0.79 seconds \t| Total (136.59)\n",
      "Time taken (Embedding (batch 171)) = 0.79 seconds \t| Total (137.38)\n",
      "Time taken (Embedding (batch 172)) = 0.78 seconds \t| Total (138.16)\n",
      "Time taken (Embedding (batch 173)) = 0.82 seconds \t| Total (138.98)\n",
      "Time taken (Embedding (batch 174)) = 0.82 seconds \t| Total (139.79)\n",
      "Time taken (Embedding (batch 175)) = 0.79 seconds \t| Total (140.58)\n",
      "Time taken (Embedding (batch 176)) = 0.78 seconds \t| Total (141.36)\n",
      "Time taken (Embedding (batch 177)) = 0.79 seconds \t| Total (142.15)\n",
      "Time taken (Embedding (batch 178)) = 0.78 seconds \t| Total (142.93)\n",
      "Time taken (Embedding (batch 179)) = 0.82 seconds \t| Total (143.75)\n",
      "Time taken (Embedding (batch 180)) = 0.79 seconds \t| Total (144.54)\n",
      "Time taken (Embedding (batch 181)) = 0.78 seconds \t| Total (145.32)\n",
      "58 168\n"
     ]
    }
   ],
   "source": [
    "#CPU - single sequence save\n",
    "def EmbeddingGeneration(inputlist, outdir, model):\n",
    "    embdic = {}\n",
    "    baduniprot = []\n",
    "    \n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #Load model to gpu\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            \n",
    "        batch_labels = None \n",
    "        batch_strs   = None\n",
    "        batch_tokens = None\n",
    "        \n",
    "        start = time.time()\n",
    "        #Tokenise + pad sequences\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(inputlist)\n",
    "        #Dictionary for matching Uniprot <> Token\n",
    "        comdic = dict(zip(batch_labels, batch_tokens))\n",
    "        truestart = time.time()\n",
    "        #Iterate over chunks of seqs\n",
    "        for ent in range(len(batch_tokens)):\n",
    "            start = time.time()\n",
    "            #Clear GPU memory\n",
    "            out          = None\n",
    "            batch_subset = None\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            #if os.path.exists(outdir+batch_labels[ent]+\".pt\") == False:\n",
    "            try:\n",
    "                batch_subset = batch_tokens[ent].to(device=\"cuda\", non_blocking=True)\n",
    "                out = model(batch_subset.unsqueeze(0), repr_layers=[33], return_contacts=False)[\"representations\"][33]\n",
    "                out = out.cpu()\n",
    "                torch.save(out, outdir+batch_labels[ent]+\".pt\")\n",
    "                embdic.setdefault(batch_labels[ent], out)\n",
    "            except:\n",
    "                print(f\"\\nIssue! = {chunk, batch_labels[ent]}\")\n",
    "                print(f\"Pre - Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "                print(f\"Pre - Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "                baduniprot.append(batch_labels[ent])\n",
    "          #  else:\n",
    "                print(f\"Exists - {batch_labels[ent]+\".pt\"}\")\n",
    "            print(f\"Time taken (Embedding (batch {ent})) = {round(time.time()-start, 2)} seconds \\t| Total ({round(time.time()-truestart, 2)})\")\n",
    "\n",
    "    return embdic, baduniprot\n",
    "\n",
    "testdic, baduniprot = EmbeddingGeneration(testlist, datadir+\"/Leishmaniasis_embed/test/\", model)\n",
    "traindic, baduniprot = EmbeddingGeneration(trainlist, datadir+\"/Leishmaniasis_embed/train/\", model)\n",
    "\n",
    "for i in testdic:\n",
    "    testdic[i] = [float(round(smallseqs.loc[smallseqs[\"Uniprot\"] == i][\"Score\"].values[0], 3)), testdic[i]]\n",
    "\n",
    "for i in traindic:\n",
    "    traindic[i] = [float(round(smallseqs.loc[smallseqs[\"Uniprot\"] == i][\"Score\"].values[0], 3)), traindic[i]]\n",
    "\n",
    "print(len(testdic), len(traindic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93844e16-383b-4bdc-8b11-9e84612552ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(np.float64(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bf997a5-1a9d-451d-a757-6071f2e98301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, tensor([[[ 0.0351, -0.0081,  0.0275,  ..., -0.1981,  0.0471, -0.0036],\n",
      "         [ 0.1278, -0.0170, -0.0547,  ...,  0.2933,  0.0029,  0.1559],\n",
      "         [ 0.0441, -0.1781,  0.1449,  ...,  0.1955,  0.2921,  0.3168],\n",
      "         ...,\n",
      "         [ 0.0350,  0.1062,  0.0308,  ..., -0.2161,  0.1026,  0.0445],\n",
      "         [ 0.0320,  0.1028,  0.0235,  ..., -0.2155,  0.0947,  0.0249],\n",
      "         [ 0.0240,  0.0859,  0.0280,  ..., -0.2171,  0.1003,  0.0267]]])]\n"
     ]
    }
   ],
   "source": [
    "print(traindic[\"Q8N8Y2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cfeb459-42f6-4249-81f9-ed8e3f36f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "allflot = []\n",
    "for i in traindic:\n",
    "    if traindic[i][0] not in allflot:\n",
    "        allflot.append(traindic[i][0])\n",
    "\n",
    "print(len(allflot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48ac47-7ae6-40d2-ba63-9d9b88acdf32",
   "metadata": {},
   "source": [
    "### ML analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f032c50e-2792-412e-b82d-24318b37300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SequenceClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes):\n",
    "        super(SequenceClassifier, self).__init__()\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        _, (hidden, _) = self.rnn(x) \n",
    "        hidden = hidden[-1]\n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba1718e6-f29c-41c1-a731-38cb07c92f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()   \n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(embeddings)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Print loss\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "#Initialize Model, Loss, and Optimizer\n",
    "embedding_dim = 1280\n",
    "hidden_dim = 512\n",
    "num_classes = 23\n",
    "model = SequenceClassifier(embedding_dim, hidden_dim, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start = time.time()\n",
    "#Training Loop with Debug Prints\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    model.train()\n",
    "    for i in traindic:\n",
    "        labels, embeddings = traindic[i]\n",
    "        labels = torch.tensor([labels])\n",
    "        optimizer.zero_grad()   \n",
    "        outputs = model(embeddings)  # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(f\"{i} - Loss: {loss.item()}\")  # Print loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f\"Time taken (Load embeddings) = {round(time.time()-start, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9aec4f9-1663-4939-9571-37a220fca9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P01303': [np.float64(0.002),\n",
       "  tensor([[[ 0.0519,  0.0064,  0.0787,  ..., -0.2606,  0.1738, -0.0135],\n",
       "           [-0.0059,  0.0888, -0.0782,  ...,  0.1215, -0.0497, -0.0010],\n",
       "           [-0.1509,  0.1993,  0.2442,  ...,  0.0825,  0.2186, -0.0241],\n",
       "           ...,\n",
       "           [ 0.0366, -0.0666,  0.1165,  ..., -0.2293,  0.1767,  0.0809],\n",
       "           [ 0.0415, -0.0719,  0.1119,  ..., -0.2167,  0.1765,  0.0868],\n",
       "           [ 0.0560, -0.0870,  0.1015,  ..., -0.1909,  0.2290,  0.1087]]])],\n",
       " 'P01825': [np.float64(0.587),\n",
       "  tensor([[[ 0.0619, -0.0027,  0.0128,  ..., -0.2464,  0.1543,  0.0157],\n",
       "           [ 0.0181,  0.1384, -0.0895,  ...,  0.1380,  0.0264,  0.1064],\n",
       "           [-0.1832,  0.1850, -0.2596,  ...,  0.0671,  0.0291, -0.1657],\n",
       "           ...,\n",
       "           [-0.1874, -0.4130, -0.0949,  ..., -0.2987, -0.0400,  0.0886],\n",
       "           [-0.1365, -0.3596,  0.0068,  ..., -0.3444, -0.0401,  0.0616],\n",
       "           [-0.0426, -0.2834,  0.0861,  ..., -0.1982, -0.0037,  0.1315]]])],\n",
       " 'P01601': [np.float64(0.587),\n",
       "  tensor([[[ 0.0891, -0.0009,  0.0232,  ..., -0.2107,  0.1536,  0.0432],\n",
       "           [ 0.1451, -0.0215, -0.0977,  ...,  0.2257,  0.0728,  0.0790],\n",
       "           [-0.0493, -0.0059, -0.1500,  ...,  0.1873,  0.2496,  0.1563],\n",
       "           ...,\n",
       "           [ 0.1124, -0.1075, -0.0171,  ..., -0.2840,  0.1804,  0.1403],\n",
       "           [ 0.1293, -0.1157,  0.0266,  ..., -0.2429,  0.1233,  0.1721],\n",
       "           [ 0.1008,  0.0279,  0.2478,  ..., -0.1010,  0.1987,  0.2759]]])],\n",
       " 'P29274': [np.float64(0.092),\n",
       "  tensor([[[ 0.0169,  0.0088,  0.0528,  ..., -0.2871,  0.1237, -0.0070],\n",
       "           [ 0.0694,  0.0536,  0.1223,  ...,  0.1005,  0.0865,  0.1931],\n",
       "           [-0.0694, -0.1597,  0.0133,  ..., -0.0143,  0.1023, -0.0125],\n",
       "           ...,\n",
       "           [-0.0081, -0.1342, -0.1235,  ...,  0.1406, -0.1359,  0.2418],\n",
       "           [ 0.0753, -0.1025, -0.1188,  ..., -0.0231, -0.2049,  0.1016],\n",
       "           [ 0.1189, -0.0065,  0.0526,  ...,  0.1141,  0.0581,  0.2893]]])],\n",
       " 'P05112': [np.float64(0.004),\n",
       "  tensor([[[ 0.0327, -0.0004,  0.0938,  ..., -0.2165,  0.1671, -0.0621],\n",
       "           [-0.1988,  0.0359,  0.0130,  ...,  0.1251, -0.1919, -0.0978],\n",
       "           [-0.0583,  0.3322, -0.1340,  ...,  0.1037, -0.0089, -0.0766],\n",
       "           ...,\n",
       "           [ 0.0633, -0.0348, -0.0319,  ..., -0.0996, -0.0141, -0.0678],\n",
       "           [ 0.0656, -0.0512, -0.0352,  ..., -0.1109, -0.0587,  0.0034],\n",
       "           [ 0.0966, -0.1192,  0.0092,  ..., -0.1429, -0.1206, -0.0948]]])],\n",
       " 'Q16552': [np.float64(0.006),\n",
       "  tensor([[[ 0.0425, -0.0111,  0.0361,  ..., -0.2371,  0.1393, -0.0504],\n",
       "           [-0.0498, -0.1387, -0.0385,  ...,  0.2026, -0.1498, -0.1914],\n",
       "           [-0.0392,  0.2735,  0.0983,  ...,  0.0187,  0.0396, -0.0941],\n",
       "           ...,\n",
       "           [-0.2483, -0.1178, -0.1743,  ..., -0.0575, -0.2414, -0.4804],\n",
       "           [ 0.0541, -0.3299, -0.0232,  ..., -0.1897,  0.1225, -0.1235],\n",
       "           [ 0.0802, -0.2948,  0.0673,  ..., -0.1046, -0.0839, -0.2164]]])],\n",
       " 'P05113': [np.float64(0.002),\n",
       "  tensor([[[ 0.0555,  0.0014,  0.1070,  ..., -0.2264,  0.1531, -0.0356],\n",
       "           [-0.1006, -0.0815, -0.1001,  ...,  0.0945, -0.0429, -0.1516],\n",
       "           [-0.1458,  0.1811, -0.0431,  ...,  0.1615, -0.0456, -0.0289],\n",
       "           ...,\n",
       "           [ 0.1202, -0.0592,  0.0246,  ..., -0.0731, -0.0284, -0.0061],\n",
       "           [ 0.1273, -0.1255, -0.0275,  ..., -0.0882, -0.0694,  0.0079],\n",
       "           [ 0.0974, -0.1471,  0.0601,  ..., -0.0781, -0.0830,  0.0109]]])],\n",
       " 'P01861': [np.float64(0.587),\n",
       "  tensor([[[ 2.0051e-02, -6.8921e-03, -1.6813e-02,  ..., -2.7323e-01,\n",
       "             1.8046e-01, -7.7203e-03],\n",
       "           [ 1.3610e-02,  1.6027e-01, -7.6723e-02,  ...,  8.9373e-02,\n",
       "             3.6471e-03, -1.4879e-01],\n",
       "           [ 1.1871e-01,  1.7220e-01, -1.4571e-01,  ..., -3.3799e-02,\n",
       "            -2.5822e-01, -1.7273e-01],\n",
       "           ...,\n",
       "           [ 2.1119e-01, -2.6304e-01, -3.4557e-01,  ...,  1.3952e-01,\n",
       "            -1.8824e-04, -1.1946e-01],\n",
       "           [ 4.6908e-02, -3.7286e-01, -3.7829e-02,  ...,  1.3294e-01,\n",
       "            -1.5587e-01, -5.4271e-02],\n",
       "           [-4.1892e-02, -4.3845e-01, -1.5394e-01,  ...,  1.0431e-01,\n",
       "            -3.9423e-02, -2.4465e-02]]])],\n",
       " 'P46108': [np.float64(0.462),\n",
       "  tensor([[[ 0.0552,  0.0094,  0.0362,  ..., -0.2728,  0.1833,  0.0320],\n",
       "           [-0.0667, -0.1652, -0.1150,  ...,  0.1149, -0.0012,  0.2097],\n",
       "           [-0.0371,  0.1467, -0.3644,  ...,  0.0362,  0.0709,  0.0580],\n",
       "           ...,\n",
       "           [ 0.0112, -0.1631, -0.1783,  ..., -0.2209,  0.0515,  0.1048],\n",
       "           [ 0.0520, -0.1123, -0.0234,  ..., -0.2726,  0.1775,  0.0851],\n",
       "           [ 0.0334, -0.2140, -0.1699,  ..., -0.2383,  0.0468,  0.0393]]])],\n",
       " 'P04439': [np.float64(0.001),\n",
       "  tensor([[[ 0.0445, -0.0048,  0.0803,  ..., -0.2522,  0.2002,  0.0252],\n",
       "           [ 0.0224, -0.0435, -0.0604,  ...,  0.1418, -0.0349,  0.1046],\n",
       "           [-0.1761,  0.3402, -0.1539,  ...,  0.0182,  0.1449,  0.1802],\n",
       "           ...,\n",
       "           [-0.0208, -0.0580, -0.1141,  ...,  0.0124, -0.1316,  0.0365],\n",
       "           [-0.1859, -0.1287, -0.0333,  ...,  0.0539, -0.1000,  0.1174],\n",
       "           [-0.2078, -0.0853, -0.1639,  ..., -0.0184,  0.0129,  0.0176]]])],\n",
       " 'P29466': [np.float64(0.012),\n",
       "  tensor([[[ 0.0268, -0.0526,  0.0762,  ..., -0.3047,  0.2040,  0.0281],\n",
       "           [ 0.0599,  0.0091, -0.3286,  ...,  0.0246, -0.0437,  0.1017],\n",
       "           [-0.2083,  0.2336, -0.2284,  ...,  0.0573, -0.0857,  0.3242],\n",
       "           ...,\n",
       "           [ 0.1672, -0.2297, -0.4156,  ...,  0.0136, -0.0369, -0.2562],\n",
       "           [ 0.1821,  0.0634, -0.3525,  ..., -0.0718, -0.0044, -0.1703],\n",
       "           [ 0.1181, -0.1870, -0.3395,  ..., -0.1029, -0.1782, -0.0798]]])],\n",
       " 'Q9BZS1': [np.float64(0.005),\n",
       "  tensor([[[ 0.0642,  0.0069,  0.0807,  ..., -0.2686,  0.1799, -0.0261],\n",
       "           [ 0.0627, -0.0263,  0.0107,  ...,  0.0186, -0.0684,  0.1162],\n",
       "           [ 0.0448, -0.0151,  0.1068,  ..., -0.1502,  0.1725,  0.0682],\n",
       "           ...,\n",
       "           [-0.0265, -0.1107, -0.0357,  ..., -0.0494,  0.2064,  0.1048],\n",
       "           [-0.0016, -0.0644, -0.1139,  ..., -0.1077,  0.1880,  0.0363],\n",
       "           [ 0.0066, -0.1607, -0.0438,  ..., -0.0692,  0.1487,  0.1441]]])],\n",
       " 'P01911': [np.float64(0.001),\n",
       "  tensor([[[ 0.0355,  0.0437,  0.0522,  ..., -0.2299,  0.1978,  0.0408],\n",
       "           [ 0.0257,  0.0378,  0.0279,  ...,  0.1874, -0.1829,  0.0565],\n",
       "           [ 0.0241,  0.2362,  0.1945,  ...,  0.0808,  0.1035, -0.0585],\n",
       "           ...,\n",
       "           [-0.1860, -0.0181,  0.0265,  ...,  0.1712,  0.0092,  0.1484],\n",
       "           [-0.1059, -0.0423, -0.1843,  ...,  0.1330,  0.2589,  0.1004],\n",
       "           [-0.1195, -0.0535, -0.1256,  ..., -0.0657, -0.1607,  0.2678]]])],\n",
       " 'P00441': [np.float64(0.016),\n",
       "  tensor([[[ 0.0759,  0.0206, -0.0020,  ..., -0.2811,  0.1506,  0.0216],\n",
       "           [ 0.2087,  0.0467, -0.1542,  ..., -0.0170, -0.1201,  0.1732],\n",
       "           [ 0.0707,  0.2883, -0.1362,  ..., -0.2643,  0.1186,  0.0122],\n",
       "           ...,\n",
       "           [ 0.1424, -0.1182, -0.1888,  ..., -0.3408, -0.0390, -0.0813],\n",
       "           [ 0.1276, -0.0983, -0.1142,  ..., -0.3336,  0.0566, -0.0296],\n",
       "           [ 0.2173,  0.0704, -0.1595,  ..., -0.0781, -0.1040,  0.1236]]])],\n",
       " 'P01562': [np.float64(0.001),\n",
       "  tensor([[[ 0.0134, -0.0454,  0.1320,  ..., -0.2979,  0.2360,  0.0435],\n",
       "           [-0.3119, -0.0185, -0.1365,  ..., -0.0874, -0.0171,  0.0694],\n",
       "           [-0.5828,  0.4888, -0.1945,  ..., -0.1203,  0.2030, -0.0875],\n",
       "           ...,\n",
       "           [-0.1159, -0.0470, -0.0726,  ..., -0.1501,  0.1625,  0.0919],\n",
       "           [-0.0302, -0.0800,  0.0557,  ..., -0.2504,  0.1548,  0.0721],\n",
       "           [-0.1375, -0.0141, -0.0540,  ..., -0.2262, -0.1260,  0.0016]]])],\n",
       " 'P00156': [np.float64(0.001),\n",
       "  tensor([[[ 0.0285,  0.0297,  0.0420,  ..., -0.2598,  0.1057, -0.0283],\n",
       "           [ 0.0670, -0.2337,  0.0799,  ...,  0.0591,  0.0820,  0.1859],\n",
       "           [ 0.0628, -0.0176, -0.0661,  ..., -0.0514,  0.0670, -0.0356],\n",
       "           ...,\n",
       "           [ 0.2267, -0.1837,  0.1818,  ..., -0.1476,  0.0156, -0.0818],\n",
       "           [ 0.2438, -0.0870,  0.1098,  ..., -0.1558, -0.1880, -0.0252],\n",
       "           [ 0.1319, -0.0712,  0.0599,  ..., -0.0945, -0.1681, -0.0586]]])],\n",
       " 'P01709': [np.float64(0.587),\n",
       "  tensor([[[ 0.0970, -0.0185,  0.0011,  ..., -0.2236,  0.1685,  0.0607],\n",
       "           [ 0.0692,  0.1366, -0.1608,  ...,  0.0202,  0.1043,  0.1411],\n",
       "           [-0.0890,  0.3959, -0.0881,  ..., -0.0176,  0.1881, -0.1212],\n",
       "           ...,\n",
       "           [-0.0770, -0.1757, -0.0724,  ..., -0.3002,  0.0417,  0.2077],\n",
       "           [ 0.0139, -0.2200, -0.1514,  ..., -0.3175,  0.1714,  0.2754],\n",
       "           [ 0.0511, -0.1910, -0.1200,  ..., -0.2511,  0.2229,  0.2326]]])],\n",
       " 'P19525': [np.float64(0.002),\n",
       "  tensor([[[ 0.0661, -0.0249,  0.0810,  ..., -0.2398,  0.1669,  0.0554],\n",
       "           [ 0.0186, -0.0673,  0.0255,  ...,  0.1313, -0.2480,  0.1346],\n",
       "           [ 0.0642,  0.1194,  0.0663,  ..., -0.1944,  0.0701,  0.2908],\n",
       "           ...,\n",
       "           [ 0.0551, -0.0680, -0.0162,  ..., -0.0602,  0.1366,  0.1041],\n",
       "           [ 0.0788, -0.1157, -0.0015,  ..., -0.0442,  0.2444,  0.0559],\n",
       "           [ 0.0677, -0.0865, -0.0465,  ..., -0.0297,  0.1898,  0.0726]]])],\n",
       " 'P01824': [np.float64(0.587),\n",
       "  tensor([[[ 0.0652, -0.0015,  0.0086,  ..., -0.2549,  0.1584, -0.0084],\n",
       "           [ 0.1430, -0.1342,  0.1210,  ...,  0.2592,  0.0015,  0.1362],\n",
       "           [-0.0210, -0.0013, -0.0883,  ...,  0.1757,  0.2153,  0.0780],\n",
       "           ...,\n",
       "           [-0.1484, -0.1832, -0.1688,  ..., -0.1349,  0.0167,  0.1107],\n",
       "           [ 0.0153, -0.2996,  0.0280,  ..., -0.0090,  0.1139,  0.0823],\n",
       "           [ 0.0916, -0.3412,  0.2005,  ..., -0.0505,  0.0400, -0.1163]]])],\n",
       " 'P02768': [np.float64(0.001),\n",
       "  tensor([[[ 0.0767,  0.0051,  0.1026,  ..., -0.3103,  0.1645,  0.0048],\n",
       "           [-0.0658, -0.0641, -0.1116,  ...,  0.1056, -0.1337,  0.0899],\n",
       "           [-0.1504,  0.1961, -0.0034,  ...,  0.0545, -0.0049, -0.0592],\n",
       "           ...,\n",
       "           [-0.0342,  0.0587, -0.2264,  ..., -0.0657, -0.1174, -0.0640],\n",
       "           [-0.0243,  0.0384, -0.2346,  ...,  0.0190, -0.0801, -0.1551],\n",
       "           [ 0.0115,  0.0818, -0.2913,  ...,  0.0022, -0.0860, -0.0082]]])],\n",
       " 'P01732': [np.float64(0.009),\n",
       "  tensor([[[ 0.0660,  0.0059,  0.0907,  ..., -0.2680,  0.1836,  0.0550],\n",
       "           [ 0.0897,  0.1221,  0.0013,  ...,  0.0040, -0.0379,  0.0807],\n",
       "           [-0.0727,  0.3099, -0.1953,  ..., -0.1676,  0.1967,  0.0316],\n",
       "           ...,\n",
       "           [-0.3576, -0.3393, -0.0654,  ..., -0.0902,  0.1860,  0.0504],\n",
       "           [-0.2430, -0.2702, -0.0836,  ..., -0.1295,  0.2546,  0.0262],\n",
       "           [-0.1370, -0.2567, -0.0494,  ..., -0.1360,  0.2044, -0.0849]]])],\n",
       " 'P01597': [np.float64(0.587),\n",
       "  tensor([[[ 0.0757, -0.0083,  0.0267,  ..., -0.2005,  0.1604,  0.0459],\n",
       "           [ 0.1814, -0.0169, -0.1103,  ...,  0.2110,  0.1365,  0.0739],\n",
       "           [-0.0868, -0.0028, -0.1752,  ...,  0.1647,  0.2995,  0.1614],\n",
       "           ...,\n",
       "           [ 0.1269, -0.1117, -0.0304,  ..., -0.3174,  0.2185,  0.1133],\n",
       "           [ 0.1294, -0.1104,  0.0082,  ..., -0.2764,  0.1361,  0.1520],\n",
       "           [ 0.1021, -0.0643,  0.0399,  ..., -0.2495,  0.1440,  0.2590]]])],\n",
       " 'A0A0C4DH73': [np.float64(0.587),\n",
       "  tensor([[[ 0.0830, -0.0076,  0.0238,  ..., -0.2047,  0.1629,  0.0378],\n",
       "           [ 0.1777, -0.0441, -0.0857,  ...,  0.2424,  0.1564,  0.0448],\n",
       "           [-0.0929, -0.0284, -0.1883,  ...,  0.2066,  0.2971,  0.1477],\n",
       "           ...,\n",
       "           [ 0.1000, -0.1537, -0.0152,  ..., -0.2837,  0.1701,  0.1231],\n",
       "           [ 0.0870, -0.1106,  0.0405,  ..., -0.1452,  0.0692,  0.1869],\n",
       "           [ 0.1056,  0.0136,  0.3353,  ...,  0.0196,  0.1061,  0.1635]]])],\n",
       " 'P0DOY3': [np.float64(0.587),\n",
       "  tensor([[[ 4.0217e-02,  3.1059e-02, -2.4717e-02,  ..., -2.3630e-01,\n",
       "             1.3293e-01, -2.7907e-02],\n",
       "           [ 1.1547e-02,  1.6027e-01,  9.9164e-02,  ...,  7.0573e-02,\n",
       "            -2.0354e-01, -1.5833e-01],\n",
       "           [-9.8318e-02, -5.9651e-02,  1.7004e-02,  ..., -2.7563e-02,\n",
       "            -2.6919e-01, -7.2854e-02],\n",
       "           ...,\n",
       "           [ 3.0629e-01, -5.3274e-02, -2.2557e-04,  ..., -1.2891e-01,\n",
       "            -2.5044e-01, -1.2193e-01],\n",
       "           [ 1.5616e-01, -1.2966e-01, -1.1691e-04,  ..., -2.4465e-01,\n",
       "            -1.6336e-01, -3.2549e-01],\n",
       "           [ 1.5083e-01, -3.3534e-01,  1.8411e-01,  ..., -8.3198e-02,\n",
       "            -8.1342e-03, -3.0504e-01]]])],\n",
       " 'P01374': [np.float64(0.001),\n",
       "  tensor([[[ 0.0578,  0.0347,  0.0356,  ..., -0.2501,  0.2108, -0.0337],\n",
       "           [ 0.1410,  0.1103, -0.0878,  ...,  0.0100,  0.0879,  0.0215],\n",
       "           [ 0.1473,  0.1823,  0.0219,  ...,  0.0894,  0.1669,  0.0274],\n",
       "           ...,\n",
       "           [ 0.0813,  0.2434, -0.0799,  ..., -0.1959, -0.0456,  0.2769],\n",
       "           [ 0.1490,  0.1229,  0.0898,  ..., -0.0601, -0.0008,  0.1547],\n",
       "           [ 0.0830, -0.0023,  0.1748,  ..., -0.0049,  0.0137,  0.1163]]])],\n",
       " 'P51160': [np.float64(0.092),\n",
       "  tensor([[[ 0.0644, -0.0049,  0.0897,  ..., -0.2462,  0.1268,  0.0837],\n",
       "           [ 0.1775, -0.0990, -0.0663,  ...,  0.0033, -0.1654,  0.1491],\n",
       "           [ 0.2339,  0.0489, -0.0116,  ...,  0.0173, -0.0337,  0.0497],\n",
       "           ...,\n",
       "           [ 0.1040,  0.2970, -0.0954,  ..., -0.0366, -0.0183,  0.1458],\n",
       "           [ 0.0980,  0.2360,  0.0774,  ...,  0.0768,  0.0202,  0.0912],\n",
       "           [-0.0102,  0.2893, -0.1512,  ..., -0.0595,  0.0218,  0.0537]]])],\n",
       " 'Q9BXN2': [np.float64(0.002),\n",
       "  tensor([[[-0.0133, -0.0532,  0.0608,  ..., -0.1985,  0.1592,  0.0151],\n",
       "           [ 0.1563, -0.1456, -0.1281,  ...,  0.3157,  0.0554,  0.0318],\n",
       "           [ 0.1217, -0.2981, -0.2345,  ...,  0.2693,  0.3226, -0.0666],\n",
       "           ...,\n",
       "           [-0.1723, -0.0941, -0.1943,  ..., -0.0584, -0.2514, -0.0435],\n",
       "           [ 0.0267, -0.0479, -0.1765,  ..., -0.0668, -0.1218, -0.0216],\n",
       "           [-0.2042,  0.0567, -0.1550,  ...,  0.0393, -0.1046, -0.1765]]])],\n",
       " 'P05362': [np.float64(0.002),\n",
       "  tensor([[[ 5.8300e-02, -1.2416e-02,  8.9936e-02,  ..., -3.0117e-01,\n",
       "             1.5838e-01,  5.0272e-02],\n",
       "           [-7.7672e-03,  1.5588e-01, -9.6830e-02,  ..., -4.6290e-02,\n",
       "            -1.3028e-01,  1.1781e-01],\n",
       "           [-5.3587e-02,  3.3143e-01, -2.5736e-01,  ...,  1.0764e-01,\n",
       "             2.9215e-01,  1.0010e-01],\n",
       "           ...,\n",
       "           [ 2.7487e-01, -1.3900e-01, -6.0589e-02,  ..., -4.4187e-02,\n",
       "             1.0655e-02, -1.1765e-01],\n",
       "           [ 1.7799e-04, -1.1358e-01, -1.0354e-01,  ..., -6.8456e-02,\n",
       "            -1.8958e-01,  9.8904e-02],\n",
       "           [ 1.2408e-01,  6.4657e-03, -5.9570e-02,  ..., -1.3071e-01,\n",
       "            -1.6030e-01,  2.1115e-01]]])],\n",
       " 'P13500': [np.float64(0.003),\n",
       "  tensor([[[ 4.8644e-02, -5.2058e-02,  5.4174e-02,  ..., -2.4561e-01,\n",
       "             1.1079e-01, -4.4467e-04],\n",
       "           [-6.8179e-02,  1.6585e-01, -3.2566e-01,  ...,  2.9361e-02,\n",
       "            -1.1780e-01, -1.2862e-01],\n",
       "           [-2.0751e-01,  1.8223e-01, -7.4438e-02,  ...,  1.3135e-03,\n",
       "            -8.9687e-03, -1.7751e-02],\n",
       "           ...,\n",
       "           [ 9.6117e-02,  6.1453e-02,  9.8226e-02,  ...,  5.3085e-02,\n",
       "            -2.2854e-01,  1.5788e-02],\n",
       "           [-2.7377e-04,  7.4491e-02, -1.2649e-01,  ..., -8.4420e-02,\n",
       "             2.5108e-02,  4.8945e-02],\n",
       "           [ 3.9232e-01,  4.1492e-02,  1.0406e-01,  ..., -2.0260e-02,\n",
       "             2.0785e-01, -8.4380e-02]]])],\n",
       " 'Q07343': [np.float64(0.092),\n",
       "  tensor([[[ 0.0789, -0.0052,  0.0986,  ..., -0.2838,  0.1484, -0.0238],\n",
       "           [ 0.1269, -0.1074, -0.0606,  ...,  0.0262, -0.0236, -0.0569],\n",
       "           [ 0.0228,  0.0400,  0.0289,  ..., -0.0069, -0.0211, -0.0494],\n",
       "           ...,\n",
       "           [ 0.0239, -0.0637, -0.0241,  ..., -0.0612,  0.0681, -0.0922],\n",
       "           [ 0.0291, -0.1438, -0.0050,  ...,  0.0030,  0.0514, -0.0862],\n",
       "           [ 0.0557, -0.1328,  0.0031,  ..., -0.0147,  0.0854, -0.0939]]])],\n",
       " 'P01768': [np.float64(0.587),\n",
       "  tensor([[[ 0.0624, -0.0324,  0.0380,  ..., -0.2184,  0.1611,  0.0560],\n",
       "           [ 0.1153,  0.1113, -0.0743,  ...,  0.2964,  0.0986,  0.1617],\n",
       "           [-0.0845,  0.1534, -0.0230,  ...,  0.2768,  0.2007, -0.0837],\n",
       "           ...,\n",
       "           [ 0.0103, -0.3964,  0.1701,  ..., -0.2074,  0.0908,  0.0248],\n",
       "           [ 0.0390, -0.3470, -0.0136,  ..., -0.3143,  0.0581,  0.0211],\n",
       "           [ 0.0178, -0.2958,  0.0399,  ..., -0.2552,  0.0501,  0.1214]]])],\n",
       " 'P35228': [np.float64(0.001),\n",
       "  tensor([[[ 0.0607, -0.0210,  0.1170,  ..., -0.2429,  0.1350, -0.0074],\n",
       "           [ 0.0724, -0.0741, -0.0201,  ...,  0.0937, -0.1691,  0.0527],\n",
       "           [-0.0254,  0.3015, -0.1126,  ...,  0.1387,  0.0723,  0.0112],\n",
       "           ...,\n",
       "           [ 0.0173, -0.0714,  0.0798,  ..., -0.1221,  0.1534, -0.0621],\n",
       "           [ 0.0222, -0.0784,  0.0799,  ..., -0.1262,  0.1564, -0.0668],\n",
       "           [ 0.0316, -0.0694,  0.0786,  ..., -0.1299,  0.1649, -0.0692]]])],\n",
       " 'P20963': [np.float64(0.582),\n",
       "  tensor([[[ 0.0319,  0.0021,  0.0505,  ..., -0.2421,  0.1337,  0.0093],\n",
       "           [-0.0185,  0.0244, -0.1584,  ..., -0.1216,  0.0113, -0.1667],\n",
       "           [-0.1481,  0.1865, -0.0863,  ...,  0.0724, -0.1083, -0.0671],\n",
       "           ...,\n",
       "           [ 0.0106, -0.1424, -0.1034,  ..., -0.2116,  0.1001,  0.0568],\n",
       "           [-0.0196, -0.1002, -0.0037,  ..., -0.2626,  0.1263,  0.0517],\n",
       "           [-0.2065, -0.3144, -0.2463,  ..., -0.1726, -0.0210,  0.2640]]])],\n",
       " 'P01857': [np.float64(0.587),\n",
       "  tensor([[[ 0.0185,  0.0014, -0.0230,  ..., -0.2694,  0.1852, -0.0072],\n",
       "           [ 0.0063,  0.1831, -0.0803,  ...,  0.0834,  0.0599, -0.1616],\n",
       "           [ 0.1213,  0.1370, -0.1795,  ..., -0.0441, -0.2328, -0.1542],\n",
       "           ...,\n",
       "           [ 0.1170, -0.2336, -0.0417,  ..., -0.2231,  0.1721, -0.1988],\n",
       "           [ 0.2270, -0.2857, -0.1089,  ..., -0.1867,  0.2267, -0.1749],\n",
       "           [ 0.1909, -0.5134, -0.0838,  ..., -0.1517, -0.0192,  0.0033]]])],\n",
       " 'P01763': [np.float64(0.587),\n",
       "  tensor([[[ 0.0571, -0.0148,  0.0389,  ..., -0.2189,  0.1558,  0.0510],\n",
       "           [ 0.1091,  0.1400, -0.0832,  ...,  0.2648,  0.1226,  0.1363],\n",
       "           [-0.0173,  0.1422, -0.0095,  ...,  0.2404,  0.1558, -0.1028],\n",
       "           ...,\n",
       "           [-0.1068, -0.4894,  0.1626,  ..., -0.3066,  0.0709,  0.0993],\n",
       "           [ 0.0291, -0.3843,  0.1046,  ..., -0.3794, -0.0260,  0.0689],\n",
       "           [-0.0709, -0.2694,  0.0701,  ..., -0.3202,  0.0445,  0.2580]]])],\n",
       " 'P01743': [np.float64(0.587),\n",
       "  tensor([[[ 0.0655, -0.0624,  0.0163,  ..., -0.2553,  0.1704,  0.0577],\n",
       "           [ 0.1394,  0.1106, -0.1972,  ...,  0.1247,  0.1635,  0.0347],\n",
       "           [-0.2028,  0.0711, -0.2495,  ..., -0.0430,  0.2364, -0.2305],\n",
       "           ...,\n",
       "           [-0.0019, -0.5975, -0.1512,  ..., -0.4053,  0.1499,  0.1227],\n",
       "           [-0.0309, -0.5665, -0.1013,  ..., -0.3161,  0.1306,  0.1642],\n",
       "           [-0.0484, -0.3172, -0.0662,  ..., -0.3855,  0.0947,  0.1585]]])],\n",
       " 'P49366': [np.float64(0.003),\n",
       "  tensor([[[ 0.0627, -0.0299,  0.0885,  ..., -0.2281,  0.1258,  0.0203],\n",
       "           [ 0.0883, -0.0832,  0.0120,  ...,  0.0835, -0.1026,  0.1222],\n",
       "           [ 0.1303, -0.1448,  0.0814,  ...,  0.0752,  0.0071,  0.0852],\n",
       "           ...,\n",
       "           [ 0.2452,  0.0073, -0.0662,  ...,  0.1058,  0.0658,  0.1157],\n",
       "           [ 0.1983, -0.0929, -0.0506,  ...,  0.0098,  0.0024,  0.1780],\n",
       "           [ 0.1074, -0.1223,  0.0277,  ..., -0.0092,  0.0116,  0.1250]]])],\n",
       " 'P27815': [np.float64(0.092),\n",
       "  tensor([[[ 0.0815,  0.0046,  0.1097,  ..., -0.2796,  0.1428, -0.0015],\n",
       "           [ 0.0860, -0.0772,  0.0684,  ...,  0.0461, -0.0583,  0.1099],\n",
       "           [ 0.1293, -0.0412,  0.1073,  ..., -0.0286,  0.1968,  0.0406],\n",
       "           ...,\n",
       "           [ 0.0821, -0.0573, -0.0232,  ..., -0.0125,  0.0597, -0.0066],\n",
       "           [ 0.0766, -0.0695, -0.0424,  ...,  0.0005,  0.0738, -0.0334],\n",
       "           [ 0.0721, -0.0865, -0.0269,  ...,  0.0026,  0.1138, -0.0455]]])],\n",
       " 'P04141': [np.float64(0.008),\n",
       "  tensor([[[ 0.0697,  0.0094,  0.1178,  ..., -0.2168,  0.1612, -0.0382],\n",
       "           [-0.0339,  0.1340, -0.0846,  ..., -0.0182, -0.0574, -0.0180],\n",
       "           [-0.1158,  0.3188,  0.0059,  ...,  0.0731, -0.0617, -0.1133],\n",
       "           ...,\n",
       "           [ 0.0839, -0.0541, -0.0439,  ..., -0.0606, -0.0705, -0.0342],\n",
       "           [-0.0259, -0.0234, -0.0773,  ..., -0.0505, -0.0095,  0.0328],\n",
       "           [ 0.0583,  0.0423, -0.0064,  ..., -0.0184, -0.0568, -0.0106]]])],\n",
       " 'P01762': [np.float64(0.587),\n",
       "  tensor([[[ 0.0562, -0.0106,  0.0261,  ..., -0.2274,  0.1570,  0.0235],\n",
       "           [ 0.0961,  0.1338, -0.0443,  ...,  0.3076,  0.0769,  0.1024],\n",
       "           [-0.0544,  0.1375, -0.0676,  ...,  0.2632,  0.1402, -0.1671],\n",
       "           ...,\n",
       "           [-0.0344, -0.4479,  0.2663,  ..., -0.3379,  0.0516,  0.0935],\n",
       "           [ 0.0386, -0.3522,  0.0643,  ..., -0.3661,  0.1020,  0.0022],\n",
       "           [-0.0893, -0.2503,  0.0528,  ..., -0.2837,  0.0612,  0.2130]]])],\n",
       " 'P34949': [np.float64(0.005),\n",
       "  tensor([[[ 0.1159, -0.0286,  0.0568,  ..., -0.2345,  0.1344,  0.0049],\n",
       "           [-0.0214, -0.0575, -0.1110,  ...,  0.0338, -0.2597,  0.0976],\n",
       "           [-0.0492,  0.2506, -0.1225,  ..., -0.0081,  0.2174, -0.1800],\n",
       "           ...,\n",
       "           [ 0.1624, -0.0724,  0.0006,  ..., -0.3165,  0.1170,  0.1790],\n",
       "           [ 0.1126, -0.1361,  0.1359,  ..., -0.4077,  0.2348, -0.0423],\n",
       "           [ 0.0232, -0.1906,  0.0549,  ..., -0.2789,  0.0484, -0.0152]]])],\n",
       " 'P01730': [np.float64(0.009),\n",
       "  tensor([[[ 0.0670, -0.0236,  0.0866,  ..., -0.2660,  0.1499,  0.0047],\n",
       "           [ 0.0103, -0.0449, -0.0766,  ...,  0.0144, -0.1599,  0.1147],\n",
       "           [-0.0702,  0.0262, -0.0588,  ..., -0.0969,  0.0928, -0.0259],\n",
       "           ...,\n",
       "           [ 0.2367, -0.0327, -0.1247,  ...,  0.0651, -0.0224, -0.0160],\n",
       "           [ 0.2321, -0.0813, -0.0661,  ...,  0.1370,  0.0447, -0.0476],\n",
       "           [ 0.2252, -0.1568, -0.1153,  ..., -0.1329, -0.0423, -0.0815]]])],\n",
       " 'P11279': [np.float64(0.001),\n",
       "  tensor([[[ 0.0435, -0.1271,  0.1252,  ..., -0.3250,  0.1428,  0.0778],\n",
       "           [-0.1332,  0.0450, -0.0606,  ..., -0.1364, -0.0845,  0.4544],\n",
       "           [-0.3890,  0.4212,  0.0520,  ...,  0.1266,  0.4409, -0.0117],\n",
       "           ...,\n",
       "           [-0.0483, -0.3054, -0.0034,  ...,  0.0492,  0.0532,  0.2857],\n",
       "           [-0.0432, -0.1380, -0.0883,  ...,  0.0628,  0.0312,  0.2287],\n",
       "           [ 0.0251, -0.1081, -0.2935,  ...,  0.1416,  0.0244,  0.2887]]])],\n",
       " 'P01375': [np.float64(0.011),\n",
       "  tensor([[[ 0.0538, -0.0228,  0.0957,  ..., -0.2734,  0.1732, -0.0131],\n",
       "           [ 0.0653, -0.1731, -0.0976,  ..., -0.0515,  0.0867, -0.0247],\n",
       "           [ 0.2859,  0.0948,  0.0032,  ...,  0.0956,  0.3172, -0.1308],\n",
       "           ...,\n",
       "           [ 0.0426, -0.0298,  0.0647,  ..., -0.2446,  0.2034,  0.1016],\n",
       "           [ 0.0144,  0.0140, -0.0440,  ..., -0.1716,  0.1656,  0.1729],\n",
       "           [ 0.0301, -0.2638,  0.0397,  ...,  0.2133, -0.0108,  0.3140]]])],\n",
       " 'P29965': [np.float64(0.002),\n",
       "  tensor([[[ 5.2631e-02, -2.6281e-04,  8.3933e-02,  ..., -2.8806e-01,\n",
       "             1.4806e-01,  1.6707e-02],\n",
       "           [ 7.8732e-02, -1.3959e-01, -1.6186e-01,  ..., -8.3037e-02,\n",
       "             3.4683e-02,  5.3187e-03],\n",
       "           [ 2.7485e-02,  1.0457e-01, -1.8085e-01,  ...,  4.1198e-03,\n",
       "             1.4213e-01,  8.1220e-02],\n",
       "           ...,\n",
       "           [ 2.1204e-01, -8.9694e-02,  1.4711e-01,  ...,  1.5207e-01,\n",
       "             1.0149e-01,  1.4528e-01],\n",
       "           [-2.2866e-02, -6.9464e-02,  9.0431e-02,  ...,  1.5423e-01,\n",
       "             2.1949e-02,  4.6901e-02],\n",
       "           [ 1.5193e-03, -2.0099e-01,  1.2020e-01,  ...,  2.1670e-01,\n",
       "            -1.5327e-01,  2.4907e-01]]])],\n",
       " 'P01133': [np.float64(0.015),\n",
       "  tensor([[[ 0.0489,  0.0301,  0.0972,  ..., -0.2470,  0.1290,  0.0313],\n",
       "           [-0.0712,  0.0365,  0.1117,  ..., -0.0085, -0.1819,  0.1117],\n",
       "           [-0.0555,  0.1309,  0.2179,  ...,  0.1020,  0.0769, -0.0850],\n",
       "           ...,\n",
       "           [-0.0224,  0.0238,  0.0429,  ...,  0.0630, -0.0475, -0.0230],\n",
       "           [ 0.0508,  0.0627,  0.1305,  ..., -0.2470,  0.0097,  0.0983],\n",
       "           [ 0.0270,  0.0034,  0.0547,  ..., -0.1702,  0.2217, -0.0402]]])],\n",
       " 'O43924': [np.float64(0.092),\n",
       "  tensor([[[ 0.0674,  0.0621,  0.0629,  ..., -0.2320,  0.1114, -0.0599],\n",
       "           [-0.0485,  0.0993,  0.0729,  ...,  0.0371, -0.0994, -0.1727],\n",
       "           [-0.0314,  0.3297,  0.0136,  ...,  0.0631, -0.0988, -0.0357],\n",
       "           ...,\n",
       "           [ 0.1458, -0.0921, -0.1021,  ...,  0.1216, -0.1243, -0.0732],\n",
       "           [ 0.0790, -0.0767, -0.0450,  ...,  0.1133, -0.0626,  0.0426],\n",
       "           [ 0.1824, -0.0905, -0.1732,  ...,  0.1315, -0.0622, -0.0109]]])],\n",
       " 'Q9UL03': [np.float64(0.001),\n",
       "  tensor([[[-0.0435,  0.0037, -0.0184,  ..., -0.3014,  0.2167,  0.1949],\n",
       "           [ 0.0130,  0.0747, -0.1980,  ..., -0.1192,  0.0749,  0.3810],\n",
       "           [-0.2430, -0.0135, -0.0049,  ..., -0.7216,  0.2813,  0.4182],\n",
       "           ...,\n",
       "           [ 0.0364, -0.0852, -0.0475,  ..., -0.0902, -0.0933,  0.0830],\n",
       "           [ 0.0163, -0.1834, -0.1981,  ..., -0.2014,  0.0591,  0.1088],\n",
       "           [-0.1277,  0.0263,  0.0037,  ...,  0.0423,  0.1016,  0.2738]]])],\n",
       " 'Q9NZQ7': [np.float64(0.007),\n",
       "  tensor([[[ 2.9640e-02,  1.4335e-02,  8.7076e-02,  ..., -2.6771e-01,\n",
       "             1.6147e-01,  9.2549e-03],\n",
       "           [-1.6281e-02,  8.1402e-02, -6.9802e-02,  ...,  7.2736e-02,\n",
       "            -1.9844e-01,  2.5575e-02],\n",
       "           [-7.6814e-03,  1.2720e-01, -5.4442e-02,  ...,  6.8327e-02,\n",
       "            -1.6209e-02,  1.5794e-01],\n",
       "           ...,\n",
       "           [-1.2192e-01,  6.9870e-02, -1.2010e-01,  ...,  2.2645e-04,\n",
       "            -1.3530e-02,  1.2246e-01],\n",
       "           [-7.2444e-02, -9.1081e-02, -2.1192e-01,  ...,  4.0303e-02,\n",
       "            -8.4108e-02,  2.4076e-01],\n",
       "           [ 2.0732e-02, -1.9138e-01, -3.0434e-01,  ...,  2.7654e-01,\n",
       "            -5.1136e-03,  1.2083e-01]]])],\n",
       " 'P10145': [np.float64(0.001),\n",
       "  tensor([[[ 0.0281,  0.0013,  0.0836,  ..., -0.2514,  0.1371,  0.0112],\n",
       "           [-0.0926,  0.0656, -0.1761,  ...,  0.1899, -0.1916, -0.1474],\n",
       "           [-0.3036,  0.3111,  0.0377,  ..., -0.0041,  0.0310, -0.1536],\n",
       "           ...,\n",
       "           [ 0.0248, -0.0629,  0.0360,  ..., -0.2799,  0.2515,  0.0765],\n",
       "           [ 0.0112, -0.0878,  0.0313,  ..., -0.2553,  0.2454,  0.0627],\n",
       "           [-0.0744, -0.0191,  0.2595,  ..., -0.1172, -0.2273, -0.0996]]])],\n",
       " 'P01619': [np.float64(0.587),\n",
       "  tensor([[[ 0.0782, -0.0016,  0.0432,  ..., -0.2005,  0.1613,  0.0529],\n",
       "           [ 0.1071,  0.1246, -0.1983,  ...,  0.2127,  0.0358,  0.0157],\n",
       "           [-0.0550,  0.0753, -0.0545,  ...,  0.2362,  0.0427, -0.0317],\n",
       "           ...,\n",
       "           [ 0.0622, -0.0523,  0.0159,  ..., -0.2565,  0.0877,  0.1472],\n",
       "           [ 0.0968,  0.0168,  0.1981,  ..., -0.0992,  0.0907,  0.1264],\n",
       "           [-0.0538, -0.1852,  0.1779,  ...,  0.0885,  0.2683,  0.3127]]])],\n",
       " 'P22301': [np.float64(0.01),\n",
       "  tensor([[[ 0.0352,  0.0194,  0.1062,  ..., -0.2480,  0.1915,  0.0063],\n",
       "           [-0.1452,  0.0865, -0.0661,  ...,  0.0520, -0.0210, -0.1270],\n",
       "           [-0.2198,  0.3754, -0.1349,  ...,  0.0462,  0.1049, -0.2202],\n",
       "           ...,\n",
       "           [ 0.0082,  0.1162, -0.0792,  ..., -0.1083, -0.0381, -0.0279],\n",
       "           [-0.0299, -0.0374,  0.0420,  ..., -0.1269, -0.0250,  0.0359],\n",
       "           [-0.0359,  0.1080,  0.0520,  ..., -0.1299, -0.0937, -0.0208]]])],\n",
       " 'O76074': [np.float64(0.092),\n",
       "  tensor([[[ 0.0370,  0.0185,  0.0910,  ..., -0.2342,  0.1202,  0.0249],\n",
       "           [ 0.0580, -0.1097, -0.0171,  ...,  0.1362, -0.0655,  0.1533],\n",
       "           [ 0.1737, -0.0458,  0.0704,  ...,  0.2041,  0.1827, -0.0228],\n",
       "           ...,\n",
       "           [ 0.0885,  0.0684, -0.0444,  ...,  0.1436, -0.1334,  0.2401],\n",
       "           [ 0.1904,  0.1768, -0.0211,  ...,  0.1675, -0.0527,  0.0299],\n",
       "           [ 0.2114,  0.1365, -0.0438,  ...,  0.1455,  0.0033,  0.0268]]])],\n",
       " 'P01593': [np.float64(0.587),\n",
       "  tensor([[[ 0.0835, -0.0044,  0.0238,  ..., -0.2088,  0.1545,  0.0444],\n",
       "           [ 0.2095, -0.0393, -0.1122,  ...,  0.1851,  0.1531,  0.0890],\n",
       "           [-0.0848, -0.0137, -0.1671,  ...,  0.1573,  0.2987,  0.2123],\n",
       "           ...,\n",
       "           [ 0.1930, -0.0490, -0.0038,  ..., -0.1278, -0.0132,  0.1965],\n",
       "           [ 0.1416, -0.0868, -0.0332,  ..., -0.2207,  0.0405,  0.1841],\n",
       "           [ 0.1463,  0.0897,  0.2179,  ..., -0.0358,  0.0931,  0.2079]]])],\n",
       " 'Q9NYK1': [np.float64(0.279),\n",
       "  tensor([[[ 0.0072,  0.0518,  0.1079,  ..., -0.2926,  0.1447,  0.0353],\n",
       "           [-0.1746,  0.0200,  0.0729,  ...,  0.0404, -0.2966, -0.0146],\n",
       "           [-0.2241,  0.1876, -0.0020,  ...,  0.0866,  0.0190,  0.0272],\n",
       "           ...,\n",
       "           [-0.0610,  0.2068, -0.2113,  ..., -0.0691,  0.0678,  0.1256],\n",
       "           [-0.2115,  0.0611, -0.2226,  ..., -0.0435,  0.0009,  0.1816],\n",
       "           [-0.2799,  0.1881, -0.1272,  ..., -0.0616, -0.0081,  0.2669]]])],\n",
       " 'Q14432': [np.float64(0.092),\n",
       "  tensor([[[ 0.0359, -0.0145,  0.1381,  ..., -0.3098,  0.1673,  0.0251],\n",
       "           [-0.0423, -0.1032,  0.1101,  ..., -0.1030,  0.0125,  0.1714],\n",
       "           [ 0.0486,  0.4012,  0.0508,  ..., -0.0470,  0.3907,  0.1116],\n",
       "           ...,\n",
       "           [-0.0176, -0.1128,  0.0941,  ..., -0.1040,  0.1430, -0.0886],\n",
       "           [-0.0140, -0.1105,  0.0944,  ..., -0.1035,  0.1411, -0.0911],\n",
       "           [-0.0162, -0.1125,  0.0922,  ..., -0.1049,  0.1437, -0.0956]]])],\n",
       " 'P01780': [np.float64(0.587),\n",
       "  tensor([[[ 0.0613, -0.0173,  0.0358,  ..., -0.2143,  0.1583,  0.0430],\n",
       "           [ 0.1288,  0.1266, -0.0814,  ...,  0.2587,  0.1112,  0.1273],\n",
       "           [-0.0147,  0.1306, -0.0267,  ...,  0.2836,  0.1538, -0.1232],\n",
       "           ...,\n",
       "           [ 0.0037, -0.3594,  0.1225,  ..., -0.1893,  0.1089,  0.1117],\n",
       "           [ 0.0326, -0.2737,  0.0744,  ..., -0.3057,  0.0079,  0.0359],\n",
       "           [ 0.0168, -0.2627,  0.0295,  ..., -0.2460,  0.0739,  0.1507]]])],\n",
       " 'A2NJV5': [np.float64(0.587),\n",
       "  tensor([[[ 0.0983,  0.0095,  0.0330,  ..., -0.2148,  0.1628,  0.0408],\n",
       "           [ 0.2354,  0.2640, -0.1701,  ...,  0.0471,  0.1447,  0.0940],\n",
       "           [-0.1181,  0.2334,  0.0272,  ...,  0.1058,  0.2828, -0.1931],\n",
       "           ...,\n",
       "           [-0.1261, -0.0964, -0.0428,  ..., -0.0537, -0.2833,  0.0266],\n",
       "           [ 0.0131, -0.0902,  0.1148,  ..., -0.0104, -0.0515,  0.1929],\n",
       "           [-0.0359, -0.0339,  0.1971,  ...,  0.0673, -0.0795,  0.1565]]])]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90e9ad-9c7c-426d-b9dc-da86a484e619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
